{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.6 (default, Jan  8 2020, 19:59:22) \n",
      "[GCC 7.3.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from IPython.display import display, Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = \"data/pop_pickle\"\n",
    "N_SAMPLES = 909\n",
    "VOCAB_SIZE = 390\n",
    "BOS_TOKEN = VOCAB_SIZE - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for i in range(N_SAMPLES):\n",
    "    file_name = str(i + 1).zfill(3) + \".pickle\"\n",
    "    path = os.path.join(DATA_ROOT, file_name)\n",
    "    with open(path, \"rb\") as f:\n",
    "        seq = pickle.load(f)\n",
    "        seq_tensor = torch.LongTensor(seq)\n",
    "    dataset.append(seq_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_lens = [len(seq) for seq in dataset]\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(seq_lens, bins=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 819 \t Val: 45 \t Test: 45\n"
     ]
    }
   ],
   "source": [
    "N_VAL = N_TEST = int(0.05 * 909)\n",
    "N_TRAIN = 909 - (N_VAL + N_TEST)\n",
    "\n",
    "train_data = dataset[:N_TRAIN]\n",
    "val_data = dataset[N_TRAIN:N_TRAIN+N_VAL]\n",
    "test_data = dataset[N_TRAIN+N_VAL:]\n",
    "\n",
    "print(f\"Train: {len(train_data)} \\t Val: {len(val_data)} \\t Test: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(seq, new_seq_len):\n",
    "    \"\"\"\n",
    "    Convert a sequence into a batch of equal-length sequences,\n",
    "    and prepend a BOS token at the start of every sequence.\n",
    "    \n",
    "    Note that the final sequences will be of length new_seq_len + 1,\n",
    "    which is desired because the extra token will be trimmed when\n",
    "    converting the sequence to x and y.\n",
    "    \"\"\"\n",
    "    num_batches = seq.size(0) // new_seq_len\n",
    "    seq = seq.narrow(dim=0, start=0, length=num_batches*new_seq_len)\n",
    "    batch = seq.view(num_batches, -1)\n",
    "    bos = torch.full(size=(num_batches, 1), fill_value=BOS_TOKEN)\n",
    "    batch = torch.cat([bos, batch], dim=1)    \n",
    "    return batch\n",
    "\n",
    "\n",
    "def compute_tokens_lost(seq, new_seq_len):\n",
    "    \"\"\"\n",
    "    Calculate the number of tokens lost when using batchify for\n",
    "    a given sequence and new_seq_len.\n",
    "    \"\"\"\n",
    "    num_batches = seq.size(0) // new_seq_len\n",
    "    new_len = num_batches * new_seq_len\n",
    "    tokens_lost = seq.size(0) - new_len\n",
    "    return tokens_lost\n",
    "\n",
    "\n",
    "def compute_total_tokens_lost(dataset, new_seq_len):\n",
    "    \"\"\"\n",
    "    Calculate the number of tokens lost when using batchify for\n",
    "    a given dataset and new_seq_len.\n",
    "    \"\"\"\n",
    "    return sum(compute_tokens_lost(seq, new_seq_len) for seq in dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 11113 \t Val: 643 \t Test: 604\n"
     ]
    }
   ],
   "source": [
    "SEQ_LEN = 512\n",
    "\n",
    "train_data = torch.cat([batchify(seq, SEQ_LEN) for seq in train_data])\n",
    "val_data = torch.cat([batchify(seq, SEQ_LEN) for seq in val_data])\n",
    "test_data = torch.cat([batchify(seq, SEQ_LEN) for seq in test_data])\n",
    "\n",
    "print(f\"Train: {len(train_data)} \\t Val: {len(val_data)} \\t Test: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 6560567\n"
     ]
    }
   ],
   "source": [
    "seq_lens = np.array([32, 64, 128, 256, 512, 1024, 2048])\n",
    "tokens_lost = np.array([compute_total_tokens_lost(dataset, seq_len) for seq_len in seq_lens])\n",
    "\n",
    "total_tokens = sum(seq.size(0) for seq in dataset)\n",
    "tokens_lost_percent = tokens_lost / total_tokens\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(seq_lens, tokens_lost_percent)\n",
    "plt.xlabel(\"Sequence length\")\n",
    "plt.ylabel(\"% tokens lost\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Total tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicRNN(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, rnn_type=\"lstm\", num_layers=1):\n",
    "        assert rnn_type in [\"lstm\", \"gru\"]\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.rnn_type = rnn_type\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        if rnn_type == \"lstm\":\n",
    "            self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True) \n",
    "        else:\n",
    "            self.rnn = nn.GRU(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "    \n",
    "        self.hidden_state = None\n",
    "\n",
    "    def forward(self, x, reset_hidden_state=True):\n",
    "        x = self.embeddings(x)\n",
    "\n",
    "        # Forward pass through RNN and FC layer.\n",
    "        if reset_hidden_state:\n",
    "            x, _ = self.rnn(x)\n",
    "        else:\n",
    "            x, self.hidden_state = self.rnn(x, self.hidden_state)\n",
    "\n",
    "        # Map to output space.\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def generate_sequence(self, seq_start=None, max_length=1024):\n",
    "        if not seq_start:\n",
    "            seq_start = [BOS_TOKEN]\n",
    "        seq = seq_start.copy()\n",
    "        with torch.no_grad():\n",
    "            next_token = self._generate_next_token(\n",
    "                model,\n",
    "                next_input=torch.LongTensor(seq).to(device),\n",
    "                reset_hidden=True,\n",
    "            )\n",
    "            while len(seq) <= max_length:\n",
    "                next_token = self._generate_next_token(\n",
    "                    model,\n",
    "                    next_input=torch.LongTensor([next_token]).to(device),\n",
    "                    reset_hidden=False,\n",
    "                )\n",
    "                seq.append(next_token)\n",
    "        return seq\n",
    "    \n",
    "    def _generate_next_token(self, model, next_input, reset_hidden=False, temp=1.0):\n",
    "        # The model expects a batch input, so we add a fake batch dimension.\n",
    "        model_input = next_input.unsqueeze(0)\n",
    "        # Then, we need to remove the fake batch dimension from the output.\n",
    "        model_output = model(model_input, reset_hidden).squeeze(0)\n",
    "        next_token_probs = F.softmax(model_output[-1] / temp, dim=0)\n",
    "        vocab = range(VOCAB_SIZE)\n",
    "        next_token = np.random.choice(vocab, p=next_token_probs.cpu().numpy())\n",
    "        return next_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now().strftime(\"%Y-%m-%d_%H:%M\")\n",
    "\n",
    "CHECKPOINT_PATH = f\"models/ckpt_{now}.pt\"\n",
    "\n",
    "EMBEDDING_DIM = 64\n",
    "HIDDEN_DIM = 128\n",
    "NUM_EPOCHS = 100\n",
    "LEARNING_RATE = 1e-3\n",
    "BATCH_SIZE = 256\n",
    "CLIPPING_THRESHOLD = 1.0\n",
    "\n",
    "LOG_EVERY_N = 1\n",
    "VAL_EVERY_N = 10\n",
    "SAVE_EVERY_N = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    collate_fn=lambda x: torch.stack(x),\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    collate_fn=lambda x: torch.stack(x),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MusicRNN(\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    rnn_type=\"lstm\",\n",
    "    num_layers=1,\n",
    ").to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MusicRNN(\n",
      "  (embeddings): Embedding(390, 64)\n",
      "  (rnn): LSTM(64, 128, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=390, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, data_loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0.0\n",
    "        for batch in data_loader:\n",
    "            batch = batch.to(device)\n",
    "            x = batch[:, :-1]\n",
    "            y = batch[:, 1:]\n",
    "            y_hat = model(x)\n",
    "            y_hat = y_hat.transpose(1, 2)\n",
    "            loss = loss_function(y_hat, y)\n",
    "            total_loss += loss.item()\n",
    "        ppl = math.exp(total_loss / len(data_loader))\n",
    "        return ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(f\"runs/lstm_exp_{now}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "358590f4ed8f486ebeebdedc6621a53c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=44.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdafcf1451684ecf9363d6426fe2be84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=44.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-602d4160842d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Back prop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Clip gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in tqdm(train_loader):\n",
    "        # Move to GPU if available.\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        # Reset gradients.\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Prepare inputs and targets.\n",
    "        x = batch[:, :-1]\n",
    "        y = batch[:, 1:]\n",
    "                \n",
    "        # Forward prop.\n",
    "        y_hat = model(x)\n",
    "        \n",
    "        # Swap token dim and output dim.\n",
    "        y_hat = y_hat.transpose(1, 2)\n",
    "        \n",
    "        # Compute loss.\n",
    "        loss = loss_function(y_hat, y)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Back prop.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Clip gradients.\n",
    "        # clip_grad_norm_(model.parameters(), CLIPPING_THRESHOLD)\n",
    "        \n",
    "        # Update parameters.\n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch % LOG_EVERY_N == 0:\n",
    "        avg_loss = total_loss / len(train_loader)  # per token loss\n",
    "        writer.add_scalar(\"train_loss\", avg_loss, global_step=epoch)\n",
    "        \n",
    "        train_ppl = math.exp(avg_loss)\n",
    "        writer.add_scalar(\"train_ppl\", train_ppl, global_step=epoch)\n",
    "\n",
    "    if epoch % VAL_EVERY_N == 0:\n",
    "        val_ppl = validate(model, val_loader)\n",
    "        writer.add_scalar(\"val_ppl\", val_ppl, global_step=epoch)\n",
    "\n",
    "    if epoch % SAVE_EVERY_N == 0:\n",
    "        state_checkpoint = {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        }\n",
    "        torch.save(state_checkpoint, CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
