{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "import nesmdb\n",
    "import numpy as np\n",
    "import pretty_midi\n",
    "from IPython.display import display, Audio\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories for the original midi data files\n",
    "MIDI_ROOT_DIR = \"data/nesmdb_midi\"\n",
    "MIDI_TRAIN_DIR = f\"{MIDI_ROOT_DIR}/train\"\n",
    "MIDI_VALID_DIR = f\"{MIDI_ROOT_DIR}/valid\"\n",
    "MIDI_TEST_DIR = f\"{MIDI_ROOT_DIR}/test\"\n",
    "\n",
    "# Output directories in which the converted event-based data will be stored\n",
    "EVENT_ROOT_DIR = \"data/nesmdb_event\"\n",
    "EVENT_TRAIN_DIR = f\"{EVENT_ROOT_DIR}/train\"\n",
    "EVENT_VALID_DIR = f\"{EVENT_ROOT_DIR}/valid\"\n",
    "EVENT_TEST_DIR = f\"{EVENT_ROOT_DIR}/test\"\n",
    "\n",
    "# Output directories for the final tokenized version of the data\n",
    "TOKEN_ROOT_DIR = \"data/nesmdb_token\"\n",
    "TOKEN_TRAIN_DIR = f\"{TOKEN_ROOT_DIR}/train\"\n",
    "TOKEN_VALID_DIR = f\"{TOKEN_ROOT_DIR}/valid\"\n",
    "TOKEN_TEST_DIR = f\"{TOKEN_ROOT_DIR}/test\"\n",
    "\n",
    "VOCAB_PATH = \"data/vocab.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in [\n",
    "    EVENT_TRAIN_DIR, EVENT_VALID_DIR, EVENT_TEST_DIR,\n",
    "    TOKEN_TRAIN_DIR, TOKEN_VALID_DIR, TOKEN_TEST_DIR,\n",
    "]:\n",
    "    os.makedirs(d, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert MIDI files to events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we convert the MIDI data to an event-based format, that represents music as `NOTEON`, `NOTEOFF`, and `WT` events, which represent notes turning on, off, and time passing, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set files: 4502\n",
      "Validation set files: 403\n",
      "Test set files: 373\n"
     ]
    }
   ],
   "source": [
    "midi_train_files = glob.glob(f\"{MIDI_TRAIN_DIR}/*.mid\")\n",
    "midi_valid_files = glob.glob(f\"{MIDI_VALID_DIR}/*.mid\")\n",
    "midi_test_files = glob.glob(f\"{MIDI_TEST_DIR}/*.mid\")\n",
    "\n",
    "print(f\"Train set files: {len(midi_train_files)}\")\n",
    "print(f\"Validation set files: {len(midi_valid_files)}\")\n",
    "print(f\"Test set files: {len(midi_test_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in tqdm(midi_train_files):\n",
    "    prepro.convert_midi_file(file, outdir=EVENT_TRAIN_DIR)\n",
    "\n",
    "for file in tqdm(midi_valid_files):\n",
    "    prepro.convert_midi_file(file, outdir=EVENT_VALID_DIR)\n",
    "\n",
    "for file in tqdm(midi_test_files):\n",
    "    prepro.convert_midi_file(file, outdir=EVENT_TEST_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert event files to tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we tokenize the event-based data by quantizing each wait time event and adding the special `BOS` and `EOS` tokens to represent the start and end of the sequence, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_train_files = glob.glob(f\"{EVENT_TRAIN_DIR}/*.txt\")\n",
    "event_valid_files = glob.glob(f\"{EVENT_VALID_DIR}/*.txt\")\n",
    "event_test_files = glob.glob(f\"{EVENT_TEST_DIR}/*.txt\")\n",
    "\n",
    "event_files = event_train_files + event_valid_files + event_test_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = utils.load_data(VOCAB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wt_to_int(wt_token):\n",
    "    \"\"\"\n",
    "    Converts \"WT_23\" to 23\n",
    "    \"\"\"\n",
    "    return int(wt_token[3:])\n",
    "\n",
    "\n",
    "wait_times = [wt_to_int(t) for t in vocab if \"WT\" in t]\n",
    "\n",
    "\n",
    "def quantize_wait_event(wt_token):\n",
    "    wait_time = wt_to_int(wt_token)\n",
    "    quant_wait_time = min(wait_times, key=lambda x: abs(x - wait_time))\n",
    "    quant_wait_event = f\"WT_{quant_wait_time}\"\n",
    "    return quant_wait_event\n",
    "\n",
    "\n",
    "def convert_event_file(infile, outdir):\n",
    "    \"\"\"Convert an event data file to a token file.\n",
    "    \n",
    "    All wait events are quantized, and the BOS and EOS tokens are\n",
    "    added at the start and end of the sequence, respectively.\n",
    "    \"\"\"\n",
    "    event_data = utils.load_data(infile)\n",
    "\n",
    "    token_data = [\n",
    "        quantize_wait_event(t) if \"WT\" in t else t\n",
    "        for t in event_data\n",
    "    ]\n",
    "    token_data.insert(0, \"BOS\")\n",
    "    token_data.append(\"EOS\")\n",
    "\n",
    "    _, fname = os.path.split(infile)\n",
    "    outfile = os.path.join(outdir, fname)\n",
    "    with open(outfile, \"w\") as f:\n",
    "        f.write(\"\\n\".join(token_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a574719951b74933a68753196f4f9e2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=403.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a171d59952d74eaf91142198eac2e704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=373.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# for file in tqdm(event_train_files):\n",
    "#     convert_event_file(file, outdir=TOKEN_TRAIN_DIR)\n",
    "\n",
    "for file in tqdm(event_valid_files):\n",
    "    convert_event_file(file, outdir=TOKEN_VALID_DIR)\n",
    "\n",
    "for file in tqdm(event_test_files):\n",
    "    convert_event_file(file, outdir=TOKEN_TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
